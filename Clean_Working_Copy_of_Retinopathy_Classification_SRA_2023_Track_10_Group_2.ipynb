{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB-aa1orEaW-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UT_s0FZcimEU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn import Conv2d\n",
        "from torchvision.transforms import Compose\n",
        "from torchvision.transforms import Resize\n",
        "from torchvision.transforms import CenterCrop\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import pil_to_tensor\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx5Dh9O1fB7D"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpmfQuwrk5iH"
      },
      "outputs": [],
      "source": [
        "data = '/content/drive/MyDrive/TrainingData_Final'\n",
        "print()\n",
        "dirs = os.listdir(data)\n",
        "dataset_old = []\n",
        "for dir in dirs:\n",
        "  for inner_dir in os.listdir(os.path.join(data, dir)):\n",
        "      dataset_old.append(os.path.join(data, dir, inner_dir))\n",
        "dataset = []\n",
        "curr = 0\n",
        "for i in dataset_old:\n",
        "  if i[42] != '5':\n",
        "    dataset.append(i)\n",
        "  elif curr < 400:\n",
        "    dataset.append(i)\n",
        "    curr += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBnU5deX5W-T"
      },
      "outputs": [],
      "source": [
        "train_set = []\n",
        "test_set = []\n",
        "validation_set = []\n",
        "for i in range(0, 6):\n",
        "  path = f\"/content/drive/MyDrive/TrainingData_Final/{i}\"\n",
        "  all_imgs_0 = os.listdir(path)\n",
        "  all_imgs_0 = [f\"{path}/{_path}\" for _path in all_imgs_0]\n",
        "  if i == 5:\n",
        "    all_imgs_0 = all_imgs_0[:400]\n",
        "  num_imgs_0 = len(all_imgs_0)\n",
        "  arr = np.arange(num_imgs_0)\n",
        "  np.random.shuffle(arr)\n",
        "  curr_tr = len(train_set)\n",
        "  curr_te = len(test_set)\n",
        "  curr_va = len(validation_set)\n",
        "  train_set += [all_imgs_0[idx] for idx in arr[0:int(0.8*num_imgs_0)]]\n",
        "  test_set += [all_imgs_0[idx]  for idx in arr[int(0.8*num_imgs_0):int(0.9*num_imgs_0)]]\n",
        "  validation_set += [all_imgs_0[idx]  for idx in arr[int(0.9*num_imgs_0):int(num_imgs_0)]]\n",
        "  print(i, 'train: ', len(train_set) - curr_tr)\n",
        "  print(i, 'test: ', len(test_set) - curr_te)\n",
        "  print(i, 'val: ', len(validation_set) - curr_va)\n",
        "  print('---')\n",
        "print('total:', len(train_set) + len(test_set) + len(validation_set))\n",
        "print('train:', len(train_set))\n",
        "print('test:', len(test_set))\n",
        "print('val:', len(validation_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDWjyKB755Gs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "labels = []\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, file_paths):\n",
        "        self.file_paths = file_paths\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.file_paths[idx]\n",
        "        image = Image.open(file_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "\n",
        "        return image, file_path[42]\n",
        "train_dataloader = DataLoader(CustomDataset(train_set), batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(CustomDataset(test_set), batch_size=64, shuffle=True)\n",
        "val_dataloader = DataLoader(CustomDataset(validation_set), batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzkBSXIZ1eRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8929686c-7374-4aec-dba1-926aad40ec06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvZliuxgXN_8"
      },
      "outputs": [],
      "source": [
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CpZzVrY1j1Q"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "      nn.Conv2d(3, 4, kernel_size=3),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride = 2),\n",
        "      nn.Conv2d(4, 8, kernel_size=3),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride = 2),\n",
        "      nn.Conv2d(8, 16, kernel_size=3),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride = 2),\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(14400, 5000),\n",
        "      nn.Linear(5000, 5),\n",
        "      nn.Softmax(dim=1)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork2, self).__init__()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "      nn.Conv2d(3, 4, kernel_size=3),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride = 2),\n",
        "      nn.Conv2d(4, 8, kernel_size=3),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride = 2),\n",
        "      nn.Conv2d(8, 16, kernel_size=3),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride = 2),\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(14400, 5000),\n",
        "      nn.Linear(5000, 2),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "u8CzVAQNoU-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t45q8xKqc22"
      },
      "outputs": [],
      "source": [
        "# 5-class\n",
        "def label_changer(y):\n",
        "  for i in range(len(y)):\n",
        "    y[i] = int(y[i])\n",
        "    if y[i] == 3 or y[i] == 5:\n",
        "      y[i] = 0\n",
        "    elif y[i] != 4:\n",
        "      y[i] += 1\n",
        "    num = y[i]\n",
        "    y[i] = torch.tensor([[0, 0, 0, 0, 0]], dtype=torch.float32)\n",
        "    y[i][0][num] = float(1)\n",
        "  y = torch.cat(y, dim=0)\n",
        "  return y\n",
        "from re import I\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)\n",
        "batch_size = 64\n",
        "loss_fn =nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    X = X.cpu()\n",
        "    y = list(y)\n",
        "    y = label_changer(y)\n",
        "    y = y.cpu()\n",
        "    pred = model(X)\n",
        "    pred = pred.to(torch.float32)\n",
        "    y = y.to(torch.float32)\n",
        "    loss = loss_fn(pred, y.argmax(1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss, current = loss.item(), batch * len(X)\n",
        "    accuracy = (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
        "    print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "    print(accuracy)\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      X = X.cpu()\n",
        "      y = list(y)\n",
        "      y = label_changer(y)\n",
        "      y = y.cpu()\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y.argmax(1)).item()\n",
        "      correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label 0: Mild Diabetic Nonproliferative Retinopathy\n",
        "\n",
        "def label_changer2(y):\n",
        "  for i in range(len(y)):\n",
        "    y[i] = int(y[i])\n",
        "    if y[i] == 0:\n",
        "      y[i] = 1\n",
        "    else:\n",
        "      y[i] = 0\n",
        "    num = y[i]\n",
        "    y[i] = torch.tensor([[0, 0]], dtype=torch.float32)\n",
        "    y[i][0][num] = float(1)\n",
        "  y = torch.cat(y, dim=0)\n",
        "  return y\n",
        "model2 = NeuralNetwork2().to(device)\n",
        "batch_size = 64\n",
        "loss_fn =nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
        "def train_loop(dataloader, model2, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X = X.cpu()\n",
        "    y = list(y)\n",
        "    y = label_changer2(y)\n",
        "    y = y.cpu()\n",
        "    pred = model2(X)\n",
        "    loss = loss_fn(pred, y.argmax(1))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss, current = loss.item(), batch * len(X)\n",
        "    print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "def test_loop(dataloader, model2, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X = X.cpu()\n",
        "      y = list(y)\n",
        "      y = label_changer2(y)\n",
        "      y = y.cpu()\n",
        "      pred = model2(X)\n",
        "      test_loss += loss_fn(pred, y.argmax(1)).item()\n",
        "      correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
        "      print(pred.argmax(1))\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "epochs = 7\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train_loop(train_dataloader, model2, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, model2, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "RrM6e1o4d3xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model2.state_dict(),  \"binary0model\")"
      ],
      "metadata": {
        "id": "SW5Sj8z_fOeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label 1: Moderate Diabetic Nonproliferative Retinopathy\n",
        "\n",
        "def label_changer2(y):\n",
        "  for i in range(len(y)):\n",
        "    y[i] = int(y[i])\n",
        "    if y[i] == 1:\n",
        "      y[i] = 1\n",
        "    else:\n",
        "      y[i] = 0\n",
        "    num = y[i]\n",
        "    y[i] = torch.tensor([[0, 0]], dtype=torch.float32)\n",
        "    y[i][0][num] = float(1)\n",
        "  y = torch.cat(y, dim=0)\n",
        "  return y\n",
        "model2 = NeuralNetwork2().to(device)\n",
        "batch_size = 64\n",
        "loss_fn =nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
        "def train_loop(dataloader, model2, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X = X.cpu()\n",
        "    y = list(y)\n",
        "    y = label_changer2(y)\n",
        "    y = y.cpu()\n",
        "    pred = model2(X)\n",
        "    loss = loss_fn(pred, y.argmax(1))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss, current = loss.item(), batch * len(X)\n",
        "    print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "def test_loop(dataloader, model2, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X = X.cpu()\n",
        "      y = list(y)\n",
        "      y = label_changer2(y)\n",
        "      y = y.cpu()\n",
        "      pred = model2(X)\n",
        "      test_loss += loss_fn(pred, y.argmax(1)).item()\n",
        "      correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "epochs = 7\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train_loop(train_dataloader, model2, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, model2, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "e8Fl_65Vd88B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model2.state_dict(),  \"binary1model\")"
      ],
      "metadata": {
        "id": "LIhdpflLfIgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label 2: Severe Diabetic Nonproliferative Retinopathy\n",
        "\n",
        "def label_changer2(y):\n",
        "  for i in range(len(y)):\n",
        "    y[i] = int(y[i])\n",
        "    if y[i] == 2:\n",
        "      y[i] = 1\n",
        "    else:\n",
        "      y[i] = 0\n",
        "    num = y[i]\n",
        "    y[i] = torch.tensor([[0, 0]], dtype=torch.float32)\n",
        "    y[i][0][num] = float(1)\n",
        "  y = torch.cat(y, dim=0)\n",
        "  return y\n",
        "model2 = NeuralNetwork2().to(device)\n",
        "batch_size = 64\n",
        "loss_fn =nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
        "def train_loop(dataloader, model2, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X = X.cpu()\n",
        "    y = list(y)\n",
        "    y = label_changer2(y)\n",
        "    y = y.cpu()\n",
        "    pred = model2(X)\n",
        "    loss = loss_fn(pred, y.argmax(1))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss, current = loss.item(), batch * len(X)\n",
        "    print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "def test_loop(dataloader, model2, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X = X.cpu()\n",
        "      y = list(y)\n",
        "      y = label_changer2(y)\n",
        "      y = y.cpu()\n",
        "      pred = model2(X)\n",
        "      test_loss += loss_fn(pred, y.argmax(1)).item()\n",
        "      correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "epochs = 7\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train_loop(train_dataloader, model2, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, model2, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "hUewMTcscp0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model2.state_dict(),  \"binary2model\")"
      ],
      "metadata": {
        "id": "dw5FXRRCfF98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLexeoXcLylg"
      },
      "outputs": [],
      "source": [
        "# label 3: Hypertensive  Retinopathy\n",
        "\n",
        "def label_changer2(y):\n",
        "  for i in range(len(y)):\n",
        "    y[i] = int(y[i])\n",
        "    if y[i] == 3:\n",
        "      y[i] = 1\n",
        "    else:\n",
        "      y[i] = 0\n",
        "    num = y[i]\n",
        "    y[i] = torch.tensor([[0, 0]], dtype=torch.float32)\n",
        "    y[i][0][num] = float(1)\n",
        "  y = torch.cat(y, dim=0)\n",
        "  return y\n",
        "model2 = NeuralNetwork2().to(device)\n",
        "batch_size = 64\n",
        "loss_fn =nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
        "def train_loop(dataloader, model2, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X = X.cpu()\n",
        "    y = list(y)\n",
        "    y = label_changer2(y)\n",
        "    y = y.cpu()\n",
        "    pred = model2(X)\n",
        "    loss = loss_fn(pred, y.argmax(1))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss, current = loss.item(), batch * len(X)\n",
        "    print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "def test_loop(dataloader, model2, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X = X.cpu()\n",
        "      y = list(y)\n",
        "      y = label_changer2(y)\n",
        "      y = y.cpu()\n",
        "      pred = model2(X)\n",
        "      test_loss += loss_fn(pred, y.argmax(1)).item()\n",
        "      correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "epochs = 7\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train_loop(train_dataloader, model2, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, model2, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model2.state_dict(),  \"binary3model\")"
      ],
      "metadata": {
        "id": "wAwfR61Ee_5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label 4: Severe Diabetic Nonproliferative Retinopathy\n",
        "\n",
        "def label_changer2(y):\n",
        "  for i in range(len(y)):\n",
        "    y[i] = int(y[i])\n",
        "    if y[i] == 4:\n",
        "      y[i] = 1\n",
        "    else:\n",
        "      y[i] = 0\n",
        "    num = y[i]\n",
        "    y[i] = torch.tensor([[0, 0]], dtype=torch.float32)\n",
        "    y[i][0][num] = float(1)\n",
        "  y = torch.cat(y, dim=0)\n",
        "  return y\n",
        "model2 = NeuralNetwork2().to(device)\n",
        "batch_size = 64\n",
        "loss_fn =nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
        "def train_loop(dataloader, model2, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X = X.cpu()\n",
        "    y = list(y)\n",
        "    y = label_changer2(y)\n",
        "    y = y.cpu()\n",
        "    pred = model2(X)\n",
        "    loss = loss_fn(pred, y.argmax(1))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss, current = loss.item(), batch * len(X)\n",
        "    print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "def test_loop(dataloader, model2, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X = X.cpu()\n",
        "      y = list(y)\n",
        "      y = label_changer2(y)\n",
        "      y = y.cpu()\n",
        "      pred = model2(X)\n",
        "      test_loss += loss_fn(pred, y.argmax(1)).item()\n",
        "      correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "epochs = 7\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train_loop(train_dataloader, model2, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, model2, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "6_g5Kt4-d_xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model2.state_dict(),  \"binary4model\")"
      ],
      "metadata": {
        "id": "1u-ijRihBmjF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Eedcdmz56TpX"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}